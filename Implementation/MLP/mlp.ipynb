{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, target = load_breast_cancer()[\"data\"], load_breast_cancer()[\"target\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.where(x < 0, np.exp(x)/(1 + np.exp(x)), 1/(1 + np.exp(-x)))\n",
    "\n",
    "class MLP(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, layer_sizes, layer_activations = [], learning_rate = 1.0):\n",
    "        self.layer_sizes = layer_sizes\n",
    "        self.layer_activations = layer_activations\n",
    "        self.learning_rate = 1.0\n",
    "    \n",
    "    def predict(self, X):\n",
    "        result = self.feed_forward(self.scaler.transform(X)).reshape(-1,1)\n",
    "        result[result > 0.5] = 1\n",
    "        result[result != 1]  = 0\n",
    "        return result\n",
    "        \n",
    "    \n",
    "    def feed_forward(self, X, return_intermediate = False):\n",
    "        \n",
    "        if return_intermediate:\n",
    "            intermediate = []\n",
    "        \n",
    "        feed = X\n",
    "        \n",
    "        for w, act in zip(self.weights, self.layer_activations):\n",
    "            bias_column = np.ones((X.shape[0], 1))\n",
    "            feed = np.append(bias_column, feed, axis=1)\n",
    "            if return_intermediate:\n",
    "                intermediate.append(feed)\n",
    "            feed = feed @ w\n",
    "            \n",
    "            if act == \"sigmoid\":\n",
    "                feed = sigmoid(feed)\n",
    "        \n",
    "        if not return_intermediate:\n",
    "            return feed\n",
    "        return feed, intermediate\n",
    "            \n",
    "    \n",
    "    def fit(self, X, y, n_steps = 10, warm_start = False, verbose = False):\n",
    "        self.scaler = StandardScaler()\n",
    "        self.scaler.fit(X)\n",
    "        X = self.scaler.transform(X)\n",
    "        \n",
    "        if not warm_start:\n",
    "            self.input_shape = X.shape[1]\n",
    "            self.weights = [np.random.rand(self.input_shape+1, self.layer_sizes[0])-0.5]\n",
    "        \n",
    "            for l_index in range(len(self.layer_sizes)-1):\n",
    "                prev_weights = np.random.rand(self.layer_sizes[l_index]+1, self.layer_sizes[l_index+1])-0.5\n",
    "                self.weights.append(prev_weights)\n",
    "            \n",
    "        while n_steps > 0:\n",
    "            if verbose:\n",
    "                print(\"Steps remaining:\", n_steps)\n",
    "            result, feeds = self.feed_forward(X, True)\n",
    "            yres = y.reshape(-1, 1)\n",
    "            deltas = [result-yres]\n",
    "            if verbose:\n",
    "                print(\"Output cross entropy:\", -1/X.shape[0]*np.sum(\n",
    "                    np.multiply(yres, np.log(result)) + np.multiply(1-yres, np.log(1-result))))\n",
    "\n",
    "            for widx in range(len(self.weights)-1, -1, -1):\n",
    "                if len(deltas) > 1:\n",
    "                    current_used = deltas[0][:,:-1]\n",
    "                else:\n",
    "                    current_used = deltas[0]\n",
    "                g_prime = np.multiply(feeds[widx], 1-feeds[widx])\n",
    "                gradient = current_used @ self.weights[widx].T\n",
    "                new_delta = np.multiply(gradient, g_prime)\n",
    "                deltas.insert(0, new_delta)\n",
    "                #print(g_prime)\n",
    "            \n",
    "            n_steps -= 1\n",
    "            \n",
    "            for idx, (feed, delta) in enumerate(zip(feeds, deltas[1:])):\n",
    "                #print(feed.T.shape, delta.shape, self.weights[idx].shape)\n",
    "                if idx != len(deltas)-2:\n",
    "                    grad = feed.T @ delta[:, :-1]\n",
    "                else:\n",
    "                    grad = feed.T @ delta\n",
    "                self.weights[idx] -= grad*self.learning_rate/X.shape[0]\n",
    "                #print(delta)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP([300, 300, 100, 1], [\"sigmoid\", \"sigmoid\", \"sigmoid\", \"sigmoid\"], learning_rate=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train, n_steps = 100, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.965034965034965"
      ]
     },
     "execution_count": 604,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(result, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = keras.Sequential([\n",
    "    keras.layers.Dense(300, activation=\"sigmoid\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(300, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(100, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.compile(\n",
    "    optimizer = \"sgd\",\n",
    "    metrics = \"accuracy\",\n",
    "    loss =\"binary_crossentropy\"\n",
    ")\n",
    "keras_model.build(input_shape = X_train.shape[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 300)               9300      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 300)               90300     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 100)               30100     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 129,801\n",
      "Trainable params: 129,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6588 - accuracy: 0.6150\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6250 - accuracy: 0.6150\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6375 - accuracy: 0.6362\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6153 - accuracy: 0.6878\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5894 - accuracy: 0.7019\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.6690\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5825 - accuracy: 0.7864\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7606\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7559\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5690 - accuracy: 0.6925\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6784\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5838 - accuracy: 0.6502\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7394\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7512\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5969 - accuracy: 0.6620\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6239 - accuracy: 0.6291\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5990 - accuracy: 0.7019\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6424 - accuracy: 0.6643\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.6385\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6063 - accuracy: 0.6080\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6596 - accuracy: 0.5869\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6787 - accuracy: 0.6150\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.6080\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6127\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6583 - accuracy: 0.6103\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5857 - accuracy: 0.7230\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6501 - accuracy: 0.6315\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6005 - accuracy: 0.6878\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5881 - accuracy: 0.7089\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.6150\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.6033\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.7488\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6174\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.7066\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7840\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.7089\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6722 - accuracy: 0.6268\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6655 - accuracy: 0.6315\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6661 - accuracy: 0.6338\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.6268\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6604 - accuracy: 0.6455\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7864\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6136 - accuracy: 0.6362\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.6150\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.8052\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5915 - accuracy: 0.7160\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5946 - accuracy: 0.6714\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5781 - accuracy: 0.6620\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7653\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7629\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6284 - accuracy: 0.6549\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5869\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6821 - accuracy: 0.6150\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6676 - accuracy: 0.6174\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6742 - accuracy: 0.6127\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6803 - accuracy: 0.6174\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.6174\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6707 - accuracy: 0.6150\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6800 - accuracy: 0.6150\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6174\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5915\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.6127\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6670 - accuracy: 0.6174\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.6150\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6709 - accuracy: 0.6150\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6696 - accuracy: 0.6174\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6740 - accuracy: 0.6150\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6721 - accuracy: 0.6174\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6664 - accuracy: 0.6150\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.6174\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6693 - accuracy: 0.6127\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6833 - accuracy: 0.6009\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6689 - accuracy: 0.6174\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.6150\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6637 - accuracy: 0.6009\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6174\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.6174\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6174\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6225 - accuracy: 0.6174\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6500 - accuracy: 0.5986\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6096 - accuracy: 0.6455\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6547 - accuracy: 0.6174\n",
      "Epoch 83/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.6150\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6792 - accuracy: 0.5845\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.6174\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6150\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6770 - accuracy: 0.6150\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6823 - accuracy: 0.5728\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6801 - accuracy: 0.6174\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.6771 - accuracy: 0.6174\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6717 - accuracy: 0.6150\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6751 - accuracy: 0.5939\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6764 - accuracy: 0.6174\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6749 - accuracy: 0.6080\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6174\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6851 - accuracy: 0.6150\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6768 - accuracy: 0.5892\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6794 - accuracy: 0.6174\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6719 - accuracy: 0.6150\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 2ms/step - loss: 0.6119 - accuracy: 0.6150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f901c67b190>"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model.fit(X_train, y_train, epochs=100, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_pred = (keras_model.predict(X_test) > 0.5).astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9230769230769231"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(keras_pred, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
