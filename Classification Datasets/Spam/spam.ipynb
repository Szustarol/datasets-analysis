{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_dirs = [\"easy_ham\", \"hard_ham\"]\n",
    "spam_dirs = [\"spam\", \"spam_2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2801 files.\n",
      "Loaded 1899 files.\n"
     ]
    }
   ],
   "source": [
    "def readDirs(dirs):\n",
    "    ret = []\n",
    "    for directory in dirs:\n",
    "        dirent = os.listdir(directory)\n",
    "        for file in dirent:\n",
    "            with open(os.path.join(directory, file), \"rb\") as f:\n",
    "                content = f.read()\n",
    "                ret += [content]\n",
    "    print(\"Loaded {} files.\".format(len(ret)))\n",
    "    return ret\n",
    "            \n",
    "\n",
    "ham_mails = readDirs(ham_dirs)\n",
    "spam_mails = readDirs(spam_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From rpm-list-admin@freshrpms.net  Thu Oct  3 12:25:27 2002\n",
      "Return-Path: <rpm-zzzlist-admin@freshrpms.net>\n",
      "Delivered-To: yyyy@localhost.example.com\n",
      "Received: from localhost (jalapeno [127.0.0.1])\n",
      "\tby jmason.org (Postfix) with ESMTP id 2707916F6D\n",
      "\tfor <jm@localhost>; Thu,  3 Oct 2002 12:24:58 +0100 (IST)\n",
      "Received: from jalapeno [127.0.0.1]\n",
      "\tby localhost with IMAP (fetchmail-5.9.0)\n",
      "\tfor jm@localhost (single-drop); Thu, 03 Oct 2002 12:24:58 +0100 (IST)\n",
      "Received: from egwn.net (auth02.nl.egwn.net [193.172.5.4]) by\n",
      "    dogma.slashnull.org (8.11.6/8.11.6) with ESMTP id g93BDgK26115 for\n",
      "    <jm-rpm@jmason.org>; Thu, 3 Oct 2002 12:13:42 +0100\n",
      "Received: from auth02.nl.egwn.net (localhost [127.0.0.1]) by egwn.net\n",
      "    (8.11.6/8.11.6/EGWN) with ESMTP id g93BA2f21504; Thu, 3 Oct 2002 13:10:02\n",
      "    +0200\n",
      "Received: from zeus.scania.co.za ([196.41.10.170]) by egwn.net\n",
      "    (8.11.6/8.11.6/EGWN) with ESMTP id g93B8uf17854 for\n",
      "    <rpm-list@freshrpms.net>; Thu, 3 Oct 2002 13:08:57 +0200\n",
      "Received: from leenx.co.za ([10.1.1.130]) by zeus.scania.co.za\n",
      "    (8.11.6/8.11.2) with ESMTP id g93B2U826023 for <rpm-list@freshrpms.net>;\n",
      "    Thu, 3 Oct 2002 13:02:35 +0200\n",
      "Message-Id: <3D9C23C5.9090203@leenx.co.za>\n",
      "From: \"C.Lee Taylor\" <leet@leenx.co.za>\n",
      "Organization: LeeNX\n",
      "User-Agent: Mozilla/5.0 (X11; U; Linux i686; en-US; rv:1.0.0) Gecko/20020607\n",
      "X-Accept-Language: en-us, en\n",
      "MIME-Version: 1.0\n",
      "To: rpm-zzzlist@freshrpms.net\n",
      "Subject: Re: alsa-driver.spec tweak for homemade kernels ...\n",
      "References: <20021003100001.29805.19626.Mailman@auth02>\n",
      "Content-Type: text/plain; charset=us-ascii; format=flowed\n",
      "Content-Transfer-Encoding: 7bit\n",
      "X-Mailscanner: Found to be clean, Found to be clean, Found to be clean\n",
      "Sender: rpm-zzzlist-admin@freshrpms.net\n",
      "Errors-To: rpm-zzzlist-admin@freshrpms.net\n",
      "X-Beenthere: rpm-zzzlist@freshrpms.net\n",
      "X-Mailman-Version: 2.0.11\n",
      "Precedence: bulk\n",
      "Reply-To: rpm-zzzlist@freshrpms.net\n",
      "List-Help: <mailto:rpm-zzzlist-request@freshrpms.net?subject=help>\n",
      "List-Post: <mailto:rpm-zzzlist@freshrpms.net>\n",
      "List-Subscribe: <http://lists.freshrpms.net/mailman/listinfo/rpm-zzzlist>,\n",
      "    <mailto:rpm-list-request@freshrpms.net?subject=subscribe>\n",
      "List-Id: Freshrpms RPM discussion list <rpm-zzzlist.freshrpms.net>\n",
      "List-Unsubscribe: <http://lists.freshrpms.net/mailman/listinfo/rpm-zzzlist>,\n",
      "    <mailto:rpm-list-request@freshrpms.net?subject=unsubscribe>\n",
      "List-Archive: <http://lists.freshrpms.net/pipermail/rpm-zzzlist/>\n",
      "X-Original-Date: Thu, 03 Oct 2002 13:02:29 +0200\n",
      "Date: Thu, 03 Oct 2002 13:02:29 +0200\n",
      "X-Spam-Status: No, hits=-2.1 required=5.0\n",
      "\ttests=KNOWN_MAILING_LIST,NOSPAM_INC,REFERENCES,USER_AGENT,\n",
      "\t      USER_AGENT_MOZILLA_UA,X_ACCEPT_LANG\n",
      "\tversion=2.50-cvs\n",
      "X-Spam-Level: \n",
      "\n",
      " >> > Well, I don't really find it consistent at all to use an rpm package\n",
      " >> > built against something that wasn't installed through rpm :-/\n",
      " >>\n",
      " >> Following that reasoning, I've been installing all my custom-built\n",
      " >> kernels through rpm recently. I find it annoying, though, that\n",
      " >> alsa-kernel, and similar packages, will only build for the currently\n",
      " >> running kernel.\n",
      " >>\n",
      " >> So I've attached a patch to specify an alternate kernel by setting the\n",
      " >> \"TARGET_KERNEL\" environment variable before running rpmbuild. You\n",
      " >> still need to have the rpm for the specified kernel installed, but at\n",
      " >> least it doesn't have to be currently running. It's kinda hackish, so\n",
      " >> if someone has a better way to do this, let me know.\n",
      " >\n",
      " >That idea looks good although it maybe needs to be tweaked a bit more (what\n",
      " >you sent doesn't support packages named \"kernel-smp\"). I'd also prefer a\n",
      " >cleaner way than the env variable, and preferrably not editing the spec...\n",
      " >probably \"--define 'target 2.4.xx-xx' --with smp\". Sound good enough?\n",
      " >The BuildRequires on \"kernel-source\" will also need to be removed because\n",
      " >it won't necessarily need to be true, and that does bug me a bit :-/\n",
      "\n",
      "\tMe and my kernel rpm builds ... this all works along the same idea I have \n",
      "been aiming for, but the freaking RedHat Kernel srpms still have been stump \n",
      "...\n",
      "\n",
      "\tIf we could get this and the alsa driver stuff working, it would be whole \n",
      "lot easier to try out a newer kernel ... but then the size of these rpms \n",
      "are huge, at least for us n^1 world courties ... ;-{ ...\n",
      "\n",
      "\tI will keep watching and hoping that somebody comes up with a great working \n",
      "idea ...\n",
      "\n",
      "Thanks guys.\n",
      "Mailed\n",
      "Lee\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "RPM-List mailing list <RPM-List@freshrpms.net>\n",
      "http://lists.freshrpms.net/mailman/listinfo/rpm-list\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ham_mails[9].decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, those emails contain a lot of header information that will be irrelevant to classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import email\n",
    "from email.parser import BytesParser\n",
    "from email.policy import default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = BytesParser(policy=default).parsebytes(ham_mails[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " >> > Well, I don't really find it consistent at all to use an rpm package\n",
      " >> > built against something that wasn't installed through rpm :-/\n",
      " >>\n",
      " >> Following that reasoning, I've been installing all my custom-built\n",
      " >> kernels through rpm recently. I find it annoying, though, that\n",
      " >> alsa-kernel, and similar packages, will only build for the currently\n",
      " >> running kernel.\n",
      " >>\n",
      " >> So I've attached a patch to specify an alternate kernel by setting the\n",
      " >> \"TARGET_KERNEL\" environment variable before running rpmbuild. You\n",
      " >> still need to have the rpm for the specified kernel installed, but at\n",
      " >> least it doesn't have to be currently running. It's kinda hackish, so\n",
      " >> if someone has a better way to do this, let me know.\n",
      " >\n",
      " >That idea looks good although it maybe needs to be tweaked a bit more (what\n",
      " >you sent doesn't support packages named \"kernel-smp\"). I'd also prefer a\n",
      " >cleaner way than the env variable, and preferrably not editing the spec...\n",
      " >probably \"--define 'target 2.4.xx-xx' --with smp\". Sound good enough?\n",
      " >The BuildRequires on \"kernel-source\" will also need to be removed because\n",
      " >it won't necessarily need to be true, and that does bug me a bit :-/\n",
      "\n",
      "\tMe and my kernel rpm builds ... this all works along the same idea I have \n",
      "been aiming for, but the freaking RedHat Kernel srpms still have been stump \n",
      "...\n",
      "\n",
      "\tIf we could get this and the alsa driver stuff working, it would be whole \n",
      "lot easier to try out a newer kernel ... but then the size of these rpms \n",
      "are huge, at least for us n^1 world courties ... ;-{ ...\n",
      "\n",
      "\tI will keep watching and hoping that somebody comes up with a great working \n",
      "idea ...\n",
      "\n",
      "Thanks guys.\n",
      "Mailed\n",
      "Lee\n",
      "\n",
      "\n",
      "_______________________________________________\n",
      "RPM-List mailing list <RPM-List@freshrpms.net>\n",
      "http://lists.freshrpms.net/mailman/listinfo/rpm-list\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(email.message_from_bytes(ham_mails[9]).get_payload())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the email body could not have been easier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's prepare those emails into a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spam = np.matrix(spam_mails).T\n",
    "X_ham = np.matrix(ham_mails).T\n",
    "\n",
    "X_data = np.concatenate([X_spam, X_ham], axis=0)\n",
    "y_data = np.concatenate((np.ones_like(X_spam, dtype=int), np.zeros_like(X_ham, dtype=int)), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4700, 1), (4700, 1))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.shape, y_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's shuffle the data before splitting into two sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data, y_data = shuffle(X_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks valid. Now, let's split the sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, train_size=0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data must be prepared. First, I will build a dictionary of words and their frequencies in the texts. I will strip both the most frequent and the most rare words, except for HTML tags, email addresses, and URLs. Also, I'll replace numbers by a separate string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "\n",
    "class MailParseDecode(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.parser = lambda x : BytesParser(policy=default).parsebytes(x).get_payload()\n",
    "        \n",
    "    def __parse(self, by):\n",
    "        out = self.parser(by)\n",
    "        if type(out) != list:\n",
    "            return out\n",
    "        else:\n",
    "            nout = \"\"\n",
    "            for o in out:\n",
    "                try:\n",
    "                    nout += str(o) + \" \"\n",
    "                except Exception:\n",
    "                    pass\n",
    "            return nout\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        cp = X.copy().astype(object)\n",
    "        for i in range(len(cp)):\n",
    "            cp[i,0] = self.__parse(X[i,0]).lower()\n",
    "        return cp\n",
    "    \n",
    "mailParseDecode = MailParseDecode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_mail_decoded = mailParseDecode.fit_transform(X_train[5,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[' TAG \\n TAG \\n\\n TAG \\n TAG \\n TAG  TAG   TAG \\n TAG  TAG \\n TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n\\t TAG \\n\\t\\t\\n     TAG   TAG  TAG  TAG  TAG \\n\\t\\t TAG \\n\\t\\t\\t TAG  TAG \\n\\t TAG \\n TAG \\n TAG  \\n TAG  \\n   TAG  TAG see this lovely celbrity &amp; many more hot stars TAG  \\n    click here TAG  TAG  TAG \\n   TAG &nbsp; TAG \\n   TAG &nbsp; TAG \\n   TAG &nbsp; TAG \\n   TAG  TAG ---------------------------------------------------------------------------------------------------------------------------------------------------------------------- TAG \\n     TAG if you would like to opt-out of future promotions  TAG click \\n    here TAG  TAG  TAG   TAG \\n   TAG \\n TAG  TAG \\n TAG \\n TAG \\n']],\n",
       "       dtype=object)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "class MailParseReplaceKeywords(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tagRegex = re.compile(r'<.*?>')\n",
    "        self.mailRegex = re.compile(r\"(^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$)\")\n",
    "        self.urlRegex = re.compile(r\"((http|https)\\:\\/\\/)?[a-zA-Z0-9\\.\\/\\?\\:@\\-_=#]+\\.([a-zA-Z]){2,6}([a-zA-Z0-9\\.\\&\\/\\?\\:@\\-_=#])*\")\n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        cp = X.copy().astype(object)\n",
    "        for i in range(len(cp)):\n",
    "            tmp = self.tagRegex.sub(' TAG ', X[i,0])\n",
    "            tmp = self.mailRegex.sub(' MAIL ', tmp)\n",
    "            cp[i,0] = self.urlRegex.sub(' URL ', tmp)\n",
    "        return cp\n",
    "    \n",
    "mailParseReplaceKeywords = MailParseReplaceKeywords()\n",
    "sample_mail_replaced = mailParseReplaceKeywords.fit_transform(sample_mail_decoded)\n",
    "sample_mail_replaced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The encoding looks correct. The next step in the pipeline would be stemming, removing punctuation, and stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from scipy.sparse import lil_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MailParseTokenizeRemove(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, lang=\"english\", keep_tokens = [\"TAG\", \"URL\", \"MAIL\"]):\n",
    "        self.lang = lang\n",
    "        self.stemmer = LancasterStemmer()\n",
    "        self.stopwords = set(stopwords.words(lang))\n",
    "        self.keep_tokens = set(keep_tokens)\n",
    "        self.vectorizer = HashingVectorizer(input=\"content\", strip_accents = \"ascii\", lowercase=False)\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    def transform(self, X, y = None):\n",
    "        cp = lil_matrix((X.shape[0], self.vectorizer.n_features))\n",
    "        for i in range(len(X)):\n",
    "            tokens = word_tokenize(X[i,0])\n",
    "            output = []\n",
    "            for token in tokens:\n",
    "                if token in self.keep_tokens:\n",
    "                    output.append(token)\n",
    "                elif token in self.stopwords:\n",
    "                    continue\n",
    "                else:\n",
    "                    output.append(self.stemmer.stem(token))\n",
    "            cp[i,:] = self.vectorizer.fit_transform([' '.join(output)])\n",
    "        return cp\n",
    "    \n",
    "mailParseTokenizeRemove = MailParseTokenizeRemove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x1048576 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mailParseTokenizeRemove.fit_transform(sample_mail_replaced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_pipeline = Pipeline([\n",
    "    (\"decode\", MailParseDecode()),\n",
    "    (\"replace\", MailParseReplaceKeywords()),\n",
    "    (\"vectorize\", MailParseTokenizeRemove())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = mail_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<3290x1048576 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 425049 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a sample classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3290, 1048576)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_transformed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.ravel().tolist()[0]\n",
    "y_test = y_test.ravel().tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "X_test_transformed = mail_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1410x1048576 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 169369 stored elements in List of Lists format>"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = rfc.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9617021276595744"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's quite a good score for a first try! I have used the test set here, but I will use cross validation to improve next models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = {\n",
    "    \"n_estimators\" : [50, 60, 70, 80, 90, 100, 110],\n",
    "    \"max_depth\" : [50, 60, 70],\n",
    "    \"min_samples_split\" : [2, 3, 4, 5, 6, 7]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_search = GridSearchCV(rfc, rfc_params, cv=3, scoring=\"accuracy\", n_jobs=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 126 candidates, totalling 378 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=8,\n",
       "             param_grid={'max_depth': [50, 60, 70],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7],\n",
       "                         'n_estimators': [50, 60, 70, 80, 90, 100, 110]},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9431628395957122"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=70, min_samples_split=3)"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.best_estimator_ #best_estimator_.n_estimators == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = {\n",
    "    \"n_estimators\" : np.linspace(95,105,10, dtype=int),\n",
    "    \"max_depth\" : [65, 75, 85, 95, 105],\n",
    "    \"min_samples_split\" : [2, 3, 4]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_search = GridSearchCV(rfc, rfc_params, cv=3, scoring=\"accuracy\", n_jobs=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 150 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=8,\n",
       "             param_grid={'max_depth': [65, 75, 85, 95, 105],\n",
       "                         'min_samples_split': [2, 3, 4],\n",
       "                         'n_estimators': array([ 95,  96,  97,  98,  99, 100, 101, 102, 103, 105])},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9559276904275541"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=105, min_samples_split=3, n_estimators=99)"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_params = {\n",
    "    \"n_estimators\" : np.linspace(98,110,10, dtype=int),\n",
    "    \"min_samples_split\" : [3],\n",
    "    \"max_depth\" : [100, 105, 110, 115]\n",
    "}\n",
    "rfc_search = GridSearchCV(rfc, rfc_params, cv=3, scoring=\"accuracy\", n_jobs=8, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 40 candidates, totalling 120 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=8,\n",
       "             param_grid={'max_depth': [100, 105, 110, 115],\n",
       "                         'min_samples_split': [3],\n",
       "                         'n_estimators': array([ 98,  99, 100, 102, 103, 104, 106, 107, 108, 110])},\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9547125316334973"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=115, min_samples_split=3, n_estimators=104)"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like the classifier improves much anymore. Let's try fitting and evaluating on the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "be = rfc_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=115, min_samples_split=3, n_estimators=104)"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "be.fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = be.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9453900709219858"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(prediction, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little less accuracy than I started with. Perhaps it would be best to just leave the max depth parameter unregularized. By any means, 96% accuracy is statisfying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
